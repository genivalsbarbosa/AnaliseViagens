{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://6337eefa6e10:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>projetoViagens</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=projetoViagens>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#init spark context and spark session\n",
    "\n",
    "# http://www.portaldatransparencia.gov.br/download-de-dados/viagens\n",
    "#\n",
    "# Viagens realizadas a servico\n",
    "#\n",
    "# CONTROLADORIA-GERAL DA UNIÃO\n",
    "#\n",
    "\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"projetoViagens\")\n",
    "spark = SparkSession.builder.appName('projetoViagens').getOrCreate()\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019_Passagem_.csv',\n",
       " '2019_Trecho_.csv',\n",
       " '2019_Viagem_.csv',\n",
       " '2019_Viagem.csv',\n",
       " '2019_Pagamento_.csv',\n",
       " '2019_Trecho.csv',\n",
       " '2019_Pagamento.csv',\n",
       " '2019_Passagem.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "all_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pandas\n",
    "#read all csv files\n",
    "#csv_files = [pd.read_csv(f, sep='\";\"').apply(lambda x: x.astype(str).str.lower()) for f in all_filenames]\n",
    "\n",
    "#for csv in csv_files:\n",
    "    #lowercase all columns\n",
    "#    csv.columns = [x.lower() for x in csv.columns]\n",
    "\n",
    "#combine all files in the list\n",
    "#combined_csv = pd.concat(csv_files, sort=False)\n",
    "\n",
    "#export to csv\n",
    "#combined_csv.to_csv( \"combined_csv.csv\", index=False, encoding='utf-8-sig', sep=';')\n",
    "\n",
    "#combined_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+---------------------+--------------------+-------------------------+----------------------+--------------+--------------------+--------------------+-------------------+----------------+--------------------+--------------------+-------------+---------------+-------------------+\n",
      "| codigov|     situacao|codigo_orgao_superior| nome_orgao_superior|codigo_orgao_solicitantev|nome_orgao_solicitante|  cpf_viajante|                nome|               cargo|periodo_data_inicio|periodo_data_fim|            destinos|              motivo|valor_diarias|valor_passagens|valor_outros_gastos|\n",
      "+--------+-------------+---------------------+--------------------+-------------------------+----------------------+--------------+--------------------+--------------------+-------------------+----------------+--------------------+--------------------+-------------+---------------+-------------------+\n",
      "|15163874|    realizada|                26000|ministério da edu...|                    26291|  fundação coordena...|***.003.00*-**|olival freire junior|professor do magi...|           20190217|        20190218|         salvador/ba|programa de profe...|          .00|        2875.92|                .00|\n",
      "|15166192|    realizada|                26000|ministério da edu...|                    26291|  fundação coordena...|***.660.31*-**|carina mendes dos...|           tecnico i|           20190220|        20190221|   rio de janeiro/rj|capacitação no ex...|          .00|        2420.48|                .00|\n",
      "|15214826|    realizada|                26000|ministério da edu...|                    26291|  fundação coordena...|***.000.46*-**|clarice madalena ...|professor do magi...|           20190215|        20190216|     porto alegre/rs|retorno de bolsis...|          .00|        2694.58|                .00|\n",
      "|15233002|não realizada|                52000|ministério da defesa|                    52121|   comando do exército|***.218.34*-**|marcos antonio am...|                 nan|           20190108|        20190111|porto alegre/rs. ...|o exmo sr gen ex ...|          .00|        1236.38|                .00|\n",
      "|15238063|    realizada|                52000|ministério da defesa|                    52121|   comando do exército|***.218.34*-**|marcos antonio am...|                 nan|           20190114|        20190115|   rio de janeiro/rj|o exmo sr. gen ex...|       481.65|         746.35|                .00|\n",
      "|15238076|    realizada|                52000|ministério da defesa|                    52121|   comando do exército|***.218.34*-**|marcos antonio am...|                 nan|           20190116|        20190117|           recife/pe|o exmo sr. gen ex...|       456.30|        1293.41|                .00|\n",
      "|15303334|    realizada|                26000|ministério da edu...|                    26258|  universidade tecn...|***.636.55*-**|adriana da silva ...|professor ens bas...|           20190126|        20190201|         salvador/ba|a proposto partic...|      1371.50|         986.15|                .00|\n",
      "|15355834|    realizada|                30000|ministério da jus...|                    30108|  departamento de p...|***.000.00*-**|informações prote...|informações prote...|           20190202|        20190202|informações prote...|informação proteg...|          .00|        1492.03|                .00|\n",
      "|15355867|    realizada|                30000|ministério da jus...|                    30108|  departamento de p...|***.000.00*-**|informações prote...|informações prote...|           20190202|        20190202|informações prote...|informação proteg...|          .00|        1492.03|                .00|\n",
      "|15387556|não realizada|                26000|ministério da edu...|                    26271|  fundação universi...|***.227.35*-**|lucio camara e silva|professor do magi...|           20190218|        20190220|         brasília/df|participação na b...|          .00|         672.60|                .00|\n",
      "|15392543|    realizada|                26000|ministério da edu...|                    26234|  universidade fede...|***.470.68*-**|yuri favalessa mo...|tecnico em anatom...|           20190113|        20190120|           maceió/al|participação em c...|          .00|        2671.65|                .00|\n",
      "|15393148|    realizada|                26000|ministério da edu...|                    26258|  universidade tecn...|***.481.27*-**|mauren louise sgu...|professor do magi...|           20190107|        20190127|        pavia/itália|visita técnica pa...|          .00|            .00|                .00|\n",
      "|15393655|não realizada|                35000|ministério das re...|                    35000|  ministério das re...|***.849.05*-**|cesar de oliveira...|         conselheiro|           20190123|        20190129|        paris/frança|remoção p/ brasun...|          .00|        3463.12|                .00|\n",
      "|15405750|    realizada|                35000|ministério das re...|                    35000|  ministério das re...|***.138.77*-**|         felipe hees|ministro de segun...|           20190105|        20190111|        pequim/china|remoção p/ brasem...|          .00|        5895.37|                .00|\n",
      "|15405941|    realizada|                26000|ministério da edu...|                    26271|  fundação universi...|***.949.99*-**|ricardo correa gomes|professor do magi...|           20190120|        20190202|milão/itália. edi...|participação em a...|          .00|        5889.17|                .00|\n",
      "|15416039|    realizada|                30000|ministério da jus...|                    30108|  departamento de p...|***.000.00*-**|informações prote...|informações prote...|           20190106|        20190107|informações prote...|informação proteg...|          .00|        4304.31|                .00|\n",
      "|15416105|    realizada|                30000|ministério da jus...|                    30108|  departamento de p...|***.000.00*-**|informações prote...|informações prote...|           20190106|        20190107|informações prote...|informação proteg...|          .00|        4304.31|                .00|\n",
      "|15421768|    realizada|                26000|ministério da edu...|                    26249|  universidade fede...|***.828.50*-**|erika maria kopp ...|professor do magi...|           20190112|        20190116|    foz do iguaçu/pr|apresentação de i...|       786.38|        1105.34|                .00|\n",
      "|15425182|    realizada|                26000|ministério da edu...|                    26251|  fundação universi...|***.193.89*-**|      taina de abreu|professor do magi...|           20190113|        20190120|           maceió/al|a servidora irá f...|      1495.40|        1775.64|                .00|\n",
      "|15425470|    realizada|                26000|ministério da edu...|                    26251|  fundação universi...|***.039.93*-**|ediana vasconcelo...|tecnico de labora...|           20190113|        20190120|           maceió/al|a servidora traba...|      1495.40|        1775.64|                .00|\n",
      "+--------+-------------+---------------------+--------------------+-------------------------+----------------------+--------------+--------------------+--------------------+-------------------+----------------+--------------------+--------------------+-------------+---------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#colunas\n",
    "#\"codigov\";\"situacao\";\"codigo_orgao_superior\";\"nome_orgao_superior\";\"codigo_orgao_solicitantev\";\"nome_orgao_solicitante\";\"cpf_viajante\";\"nome\";\"cargo\";\"periodo_data_inicio\";\"periodo_data_fim\";\"destinos\";\"motivo\";\"valor_diarias\";\"valor_passagens\";\"valor_outros_gastos\"\n",
    "#read viagem csv\n",
    "file_viagem = ['2019_Viagem_.csv']\n",
    "#file_viagem = ['2019_Viagem.csv']\n",
    "csv_viagem = [pd.read_csv(f, sep=';').apply(lambda x: x.astype(str).str.lower().str.replace(',','.')) for f in file_viagem]\n",
    "\n",
    "for csv in csv_viagem:\n",
    "    #lowercase all columns\n",
    "    csv.columns = [x.lower() for x in csv.columns]\n",
    "\n",
    "#combine all files in the list\n",
    "combined_csv_viagem = pd.concat(csv_viagem, sort=False)\n",
    "\n",
    "\n",
    "Tableviagemcsv = spark.createDataFrame(combined_csv_viagem,[\n",
    "    'codigov','situacao','codigo_orgao_superior','nome_orgao_superior','codigo_orgao_solicitantev',\n",
    "    'nome_orgao_solicitante','cpf_viajante','nome','cargo','periodo_data_inicio',\n",
    "    'periodo_data_fim','destinos','motivo','valor_diarias','valor_passagens','valor_outros_gastos'])\n",
    "\n",
    "Tableviagemcsv.write.parquet(\"Tableviagem9\")\n",
    "\n",
    "Tableviagem = spark.read.parquet(\"Tableviagem9\")\n",
    "Tableviagem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+-----------+--------------------+----------------+--------------------+------------+------------+-----------------+--------------+---------------+--------------+------+\n",
      "| codigot|sequencia_trecho|origem_data|         origem_pais|       origem_uf|       origem_cidade|destino_data|destino_pais|       destino_uf|destino_cidade|meio_transporte|numero_diarias|missao|\n",
      "+--------+----------------+-----------+--------------------+----------------+--------------------+------------+------------+-----------------+--------------+---------------+--------------+------+\n",
      "|15163874|               1|   20190217|estados unidos da...|             nan|          washington|    20190218|      brasil|            bahia|      salvador|          aéreo|           .00|   sim|\n",
      "|15166192|               1|   20190220|              itália|             nan|                roma|    20190221|      brasil|   rio de janeiro|rio de janeiro|          aéreo|           .00|   sim|\n",
      "|15214826|               1|   20190215|estados unidos da...|             nan|san francisco - c...|    20190216|      brasil|rio grande do sul|  porto alegre|          aéreo|           .00|   sim|\n",
      "|15233002|               3|   20190111|              brasil|          paraná|            curitiba|    20190111|      brasil| distrito federal|      brasília|          aéreo|           .00|   não|\n",
      "|15233002|               1|   20190108|              brasil|distrito federal|            brasília|    20190110|      brasil|rio grande do sul|  porto alegre|          aéreo|           .00|   sim|\n",
      "+--------+----------------+-----------+--------------------+----------------+--------------------+------------+------------+-----------------+--------------+---------------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#colunas\n",
    "#\"codigot\";\"sequencia_trecho\";\"origem_data\";\"origem_pais\";\"origem_uf\";\"origem_cidade\";\"destino_data\";\"destino_pais\";\"destino_uf\";\"destino_cidade\";\"meio_transporte\";\"numero_diarias\";\"missao\"\n",
    "#read trecho csv\n",
    "file_trecho = ['2019_Trecho_.csv']\n",
    "#file_trecho = ['2019_Trecho.csv']\n",
    "csv_trecho = [pd.read_csv(f, sep=';').apply(lambda x: x.astype(str).str.lower().str.replace(',','.')) for f in file_trecho]\n",
    "\n",
    "for csv in csv_trecho:\n",
    "    #lowercase all columns\n",
    "    csv.columns = [x.lower() for x in csv.columns]\n",
    "\n",
    "#combine all files in the list\n",
    "combined_csv_trecho = pd.concat(csv_trecho, sort=False)\n",
    "\n",
    "#valuesA = [('Pirate',1),('Monkey',2),('Ninja',3),('Spaghetti',4)]\n",
    "Tabletrecho = spark.createDataFrame(combined_csv_trecho,[\n",
    "    'codigot','sequencia_trecho','origem_data','origem_pais','origem_uf','origem_cidade','destino_data',\n",
    "    'destino_pais','destino_uf','destino_cidade','meio_transporte','numero_diarias','missao'])\n",
    "Tabletrecho.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colunas\n",
    "#\"codigop\";\"meio_transporte\";\"pais_origem_ida\";\"uf_origem_ida\";\"cidade_origem_ida\";\"pais_destino_ida\";\"uf_destino_ida\";\"cidade_destino_ida\";\"pais_origem_volta\";\"uf_origem_volta\";\"cidade_origem_volta\";\"pais_destino_volta\";\"uf_destino_volta\";\"cidade_destino_volta\";\"valor_passagem\";\"taxa_servico\"\n",
    "#read passagem csv\n",
    "#file_passagem = ['2019_Passagem_.csv']\n",
    "#file_passagem = ['2019_Passagem.csv']\n",
    "#csv_passagem = [pd.read_csv(f, sep=';').apply(lambda x: x.astype(str).str.lower().str.replace(',','.')) for f in file_passagem]\n",
    "\n",
    "#for csv in csv_passagem:\n",
    "    #lowercase all columns\n",
    "#    csv.columns = [x.lower() for x in csv.columns]\n",
    "\n",
    "#combine all files in the list\n",
    "#combined_csv_passagem = pd.concat(csv_passagem, sort=False)\n",
    "\n",
    "#valuesA = [('Pirate',1),('Monkey',2),('Ninja',3),('Spaghetti',4)]\n",
    "#Tablepassagem = spark.createDataFrame(combined_csv_passagem,[\n",
    "#    'codigop','meio_transporte','pais_origem_ida','uf_origem_ida','cidade_origem_ida','pais_destino_ida',\n",
    "#    'uf_destino_ida','cidade_destino_ida','pais_origem_volta','uf_origem_volta','cidade_origem_volta',\n",
    "#    'pais_destino_volta','uf_destino_volta','cidade_destino_volta','valor_passagem','taxa_servico'])\n",
    "#Tablepassagem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colunas\n",
    "#\"codigopg\";\"codigo_orgao_superior\";\"nome_orgao_superior\";\"codigo_orgao_pagador\";\"nome_orgao_pagador\";\"codigo_unidade_gestora_pagadora\";\"nome_unidade_gestora_pagadora\";\"tipo_pagamento\";\"valor\"\n",
    "#read pagamento csv\n",
    "#file_pagamento = ['2019_Pagamento_.csv']\n",
    "#file_pagamento = ['2019_Pagamento.csv']\n",
    "#csv_pagamento = [pd.read_csv(f, sep=';').apply(lambda x: x.astype(str).str.lower().str.replace(',','.')) for f in file_pagamento]\n",
    "\n",
    "#for csv in csv_pagamento:\n",
    "    #lowercase all columns\n",
    "#    csv.columns = [x.lower() for x in csv.columns]\n",
    "\n",
    "#combine all files in the list\n",
    "#combined_csv_pagamento = pd.concat(csv_pagamento, sort=False)\n",
    "\n",
    "#valuesA = [('Pirate',1),('Monkey',2),('Ninja',3),('Spaghetti',4)]\n",
    "#Tablepagamento = spark.createDataFrame(combined_csv_pagamento,[\n",
    "#    'codigopg','codigo_orgao_superior','nome_orgao_superior','codigo_orgao_pagador','nome_orgao_pagador',\n",
    "#    'codigo_unidade_gestora_pagadora','nome_unidade_gestora_pagadora','tipo_pagamento','valor'])\n",
    "#Tablepagamento.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retorno_consulta = Tableviagem.join(Tabletrecho, Tableviagem.codigov == Tabletrecho.codigot).join(Tablepassagem, Tablepassagem.codigop == Tableviagem.codigov).join(Tablepagamento, Tablepagamento.codigopg == Tablepassagem.codigop)\n",
    "retorno_consulta = Tableviagem.join(Tabletrecho, Tableviagem.codigov == Tabletrecho.codigot)\n",
    "retorno_consulta_filter = retorno_consulta.filter(\"situacao = 'realizada'\")\n",
    "#retorno_consulta_filter = Tableviagem.filter(\"situacao = 'realizada' and periodo_data_fim < '20190131'\")\n",
    "\n",
    "#retorno_consulta_filter = Tableviagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de viagens em 2019:  24\n"
     ]
    }
   ],
   "source": [
    "#quantidade de viagens em 2019\n",
    "print('Quantidade de viagens em 2019: ', retorno_consulta_filter.select('codigov').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gasto total com viagens: \n",
      "+--------------------+\n",
      "|sum(valor_passagens)|\n",
      "+--------------------+\n",
      "|  40422.990000000005|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#gasto total com viagens em 2019\n",
    "print('Gasto total com viagens: ')\n",
    "(retorno_consulta_filter.select('codigov', 'valor_passagens').distinct()).agg({'valor_passagens': 'sum'}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+----------------------+--------------------+\n",
      "|codigo_orgao_solicitantev|nome_orgao_solicitante|sum(valor_passagens)|\n",
      "+-------------------------+----------------------+--------------------+\n",
      "|                    26271|  fundação universi...|            23556.68|\n",
      "|                    39251|  agência nacional ...|            16803.32|\n",
      "|                    26291|  fundação coordena...|             7990.98|\n",
      "|                    26251|  fundação universi...|             7102.56|\n",
      "|                    26258|  universidade tecn...|              5916.9|\n",
      "|                    35000|  ministério das re...|             5895.37|\n",
      "|                    26234|  universidade fede...|              5343.3|\n",
      "|                    26249|  universidade fede...|             4421.36|\n",
      "|                    52121|   comando do exército|  4079.5200000000004|\n",
      "|                    26244|  universidade fede...|              2395.9|\n",
      "|                    26242|  universidade fede...|             1387.36|\n",
      "|                    20411|  instituto do patr...|                 0.0|\n",
      "+-------------------------+----------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# orgao que mais gastou com viagens\n",
    "retorno_consulta_filter.groupby(['codigo_orgao_solicitantev', 'nome_orgao_solicitante']).agg({'valor_passagens': 'sum'}).sort(['sum(valor_passagens)'], ascending=[0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+--------------+---------------------+\n",
      "|destino_pais|       destino_uf|destino_cidade|count(destino_cidade)|\n",
      "+------------+-----------------+--------------+---------------------+\n",
      "|      brasil| distrito federal|      brasília|                   11|\n",
      "|      brasil|       pernambuco|        recife|                    5|\n",
      "|      brasil|rio grande do sul|  porto alegre|                    4|\n",
      "|      brasil|   rio de janeiro|rio de janeiro|                    4|\n",
      "|      brasil|            bahia|      salvador|                    3|\n",
      "|      brasil|          alagoas|        maceió|                    3|\n",
      "|      brasil|        são paulo|     são paulo|                    3|\n",
      "|      brasil|           paraná|       maringá|                    2|\n",
      "|      itália|              nan|         milão|                    2|\n",
      "|      itália|              nan|         pavia|                    2|\n",
      "|      brasil|            ceará|     fortaleza|                    2|\n",
      "|      brasil|        tocantins|        palmas|                    2|\n",
      "|      brasil|           paraná| foz do iguaçu|                    1|\n",
      "| reino unido|              nan|     edimburgo|                    1|\n",
      "|      brasil|   rio de janeiro|    seropédica|                    1|\n",
      "|      brasil|         rondônia|   porto velho|                    1|\n",
      "|       china|              nan|        pequim|                    1|\n",
      "|      brasil|             pará|         belém|                    1|\n",
      "|      brasil|   espírito santo|       vitória|                    1|\n",
      "|      brasil|           paraná|  campo mourão|                    1|\n",
      "+------------+-----------------+--------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Destinos mais viajados\n",
    "retorno_consulta_filter.groupby(['destino_pais', 'destino_uf','destino_cidade']).agg({'destino_cidade': 'count'}).sort(['count(destino_cidade)'], ascending=[0]).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
